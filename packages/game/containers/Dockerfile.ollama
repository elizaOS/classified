FROM ollama/ollama:latest

# Set Ollama environment variables
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_PORT=11434

# Create directory for persistent model storage
RUN mkdir -p /root/.ollama

# Pre-download commonly used models for ELIZA
# This significantly increases image size but enables offline operation
RUN nohup ollama serve & \
    sleep 30 && \
    ollama pull llama3.2:3b && \
    ollama pull phi3:mini && \
    ollama pull qwen2.5:3b && \
    pkill ollama || true

# Expose Ollama API port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
  CMD curl -f http://localhost:11434/api/version || exit 1

# Start Ollama service
CMD ["ollama", "serve"]
